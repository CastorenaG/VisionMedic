**VisionMedic** es un sistema innovador basado en inteligencia artificial y reconocimiento facial, diseÃ±ado para evaluar el estado fÃ­sico y emocional del personal mÃ©dico antes de realizar procedimientos quirÃºrgicos.

Este proyecto fue desarrollado como parte del programa de innovaciÃ³n tecnolÃ³gica impartido por **Samsung Innovation Campus** en colaboraciÃ³n con la **Universidad de Monterrey (UDEM)**.

## ğŸ¯ Objetivo

El objetivo principal de VisionMedic es **mejorar la seguridad del paciente** mediante la **detecciÃ³n no invasiva de signos de fatiga y estrÃ©s** en los mÃ©dicos, contribuyendo asÃ­ a la **optimizaciÃ³n de la atenciÃ³n mÃ©dica**.

## ğŸ§  Â¿CÃ³mo funciona?

VisionMedic utiliza redes neuronales convolucionales (CNN) y modelos de visiÃ³n por computadora para analizar expresiones faciales y otros indicadores biomÃ©tricos. El sistema:

- EvalÃºa imÃ¡genes del rostro del personal mÃ©dico.
- Estima niveles de **cansancio**, **estrÃ©s** y **estado emocional**.
- Proporciona retroalimentaciÃ³n antes de que el mÃ©dico entre a cirugÃ­a.
- Funciona como herramienta **continua y no invasiva** para mejorar la toma de decisiones clÃ­nicas.

## ğŸ’¡ Beneficios

- âœ… Mejora la seguridad en quirÃ³fano.
- âœ… Promueve el bienestar del personal mÃ©dico.
- âœ… Integra IA de manera Ã©tica y responsable en entornos clÃ­nicos.
- âœ… Apoya decisiones en tiempo real sin interferir con el flujo de trabajo hospitalario.

## ğŸ§ª TecnologÃ­as utilizadas

- Python
- OpenCV
- DeepFace / Dlib
- TensorFlow / Keras
- CNN (Convolutional Neural Networks)
- Dataset: AffectNet, UTA-RLDD, Face Mask Detection Dataset

ğŸ“‚ Datasets Utilizados
1. AffectNet
DescripciÃ³n general: AffectNet es uno de los conjuntos de datos mÃ¡s grandes y completos para el anÃ¡lisis de emociones faciales. Contiene mÃ¡s de 1 millÃ³n de imÃ¡genes de rostros humanos, obtenidas mediante bÃºsquedas en internet y etiquetadas automÃ¡ticamente y manualmente.

Etiquetas: Las imÃ¡genes estÃ¡n clasificadas en 7 emociones bÃ¡sicas: felicidad, tristeza, enojo, miedo, sorpresa, disgusto y neutralidad. AdemÃ¡s, incluye etiquetas de valencia (placer) y arousal (nivel de activaciÃ³n), lo cual permite realizar anÃ¡lisis mÃ¡s complejos como la inferencia del estado emocional general.

Referencia: Mollahosseini, A., Hasani, B., & Mahoor, M. H. (2017). AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild. IEEE Transactions on Affective Computing.

2. UTA-RLDD (University of Texas at Arlington - Real-Life Drowsiness Dataset)
DescripciÃ³n general: UTA-RLDD es un dataset especializado en la detecciÃ³n de somnolencia en escenarios reales. Fue capturado en entornos naturales y contiene datos multimodales, incluyendo videos, secuencias de imÃ¡genes y anotaciones temporales sobre los niveles de somnolencia.

Etiquetas: Las anotaciones estÃ¡n divididas por niveles de alerta, incluyendo alerta, transiciÃ³n a somnolencia, y somnoliento. Las anotaciones se basan en marcadores como cierre ocular, cabeceo y duraciÃ³n del parpadeo.

Referencia: Vural, E., Cetin, M., & Littlewort, G. (2019). Real-life Drowsiness Detection Dataset: Collection and Analysis. IEEE International Conference on Automatic Face and Gesture Recognition (FG).

## ğŸ“ Estructura del Proyecto
VisionMedic/ 
â”‚ â”œâ”€â”€ preprocessing.py # Script de preprocesamiento con DeepFace y etiquetas manuales 
â”œâ”€â”€ train_cnn.py # Entrenamiento del modelo CNN con salida de regresiÃ³n 
â”œâ”€â”€ test_model.py # Pruebas del modelo y visualizaciÃ³n de mÃ©tricas 
â”‚ â”œâ”€â”€ X.npy # ImÃ¡genes procesadas (grises, 128x128) 
â”œâ”€â”€ y.npy # Etiquetas de nivel de fatiga [0.0, 1.0] 
â”œâ”€â”€ labels.csv # Archivo CSV con etiquetas y nombres de imagen 
â”œâ”€â”€ fatigue_model.h5 # Modelo entrenado guardado 
â”‚ â””â”€â”€ README.md # DocumentaciÃ³n del proyecto (este archivo)


## ğŸ§  TecnologÃ­as y LibrerÃ­as
- Python 3.8+
- [DeepFace](https://github.com/serengil/deepface)
- OpenCV
- TensorFlow / Keras
- NumPy,Pandas, Matplotlib, Seaborn
- scikit-learn


##ğŸš€ Fases del Proyecto
ğŸ”¹ Fase 1: Preprocesamiento de ImÃ¡genes
Script: Preprocesamiento.py
  Objetivo:    
    -Detectar rostros con DeepFace.
    -Redimensionar imÃ¡genes a 128x128 px en escala de grises.
    -Asignar etiquetas manuales de fatiga en un rango de 0.0 a 1.0.
  Salidas:
    -X.npy: ImÃ¡genes procesadas.
    -y.npy: Etiquetas numÃ©ricas.
    -labels.csv: RelaciÃ³n imagen-etiqueta.

ğŸ”¹ Fase 2: Entrenamiento del Modelo
Script: CNN.py
  Objetivo:
    -Entrenar una red neuronal convolucional (CNN) con salida de regresiÃ³n.
    -Predecir el nivel de fatiga a partir de imÃ¡genes faciales.
Modelo guardado:
    -fatigue_model.h5: Archivo del modelo entrenado.

ğŸ”¹ Fase 3: EvaluaciÃ³n y Pruebas
  Script: Prueba.py
  Objetivo:
    -Cargar el modelo entrenado.
    -Evaluar el desempeÃ±o con mÃ©tricas como Accuracy, PrecisiÃ³n,  Recall (Sensibilidad),  F1-Score.
    -Visualizar predicciones vs. valores reales.


ğŸ¯ Futuras Mejoras
IntegraciÃ³n con video en tiempo real.

ConsideraciÃ³n del uso de cubrebocas y equipo quirÃºrgico.

Entrenamiento con datasets clÃ­nicos reales y etiquetado profesional.

Panel clÃ­nico para visualizaciÃ³n rÃ¡pida del estado del equipo mÃ©dico.

ğŸ‘¨â€âš•ï¸ ContribuciÃ³n
Este proyecto fue desarrollado por Georgina Elizabeth Castorena Rojas, como parte del curso de Samsung Innovation Campus - UDEM 2024 con el objetivo de aplicar lo aprendido a travÃ©s del curso inteligencia artificial y liderazgo , junto con herramientas tecnolÃ³gicas responsables y humanas.

ğŸ“„ Licencia
Este proyecto es de uso acadÃ©mico. Para uso comercial, por favor contacta al equipo desarrollador.

